{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_indian_pines_dataset_cnn_spp_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohailkhanmarwat/Advanced-Machine-Learning-National-Research-University-Higher-School-of-Economics/blob/master/train_indian_pines_dataset_cnn_spp_rnn_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay1ved8eQp0J",
        "colab_type": "code",
        "outputId": "269970d4-1cb4-4775-e0f2-a5b95993c261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/sohailkhanmarwat/datasets.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'datasets' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3VqFaLAW0H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B5YUSaqWsUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "import os\n",
        "import keras\n",
        "import keras.layers\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten,  Activation, Input, GRU, TimeDistributed, AveragePooling2D, MaxPooling2D\n",
        "from keras.layers import Bidirectional, Conv2D, MaxPooling2D, LeakyReLU, BatchNormalization, ReLU, LSTM, RNN, Softmax, SimpleRNN\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, Adamax\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.regularizers import L1L2,l1_l2,l1,l2\n",
        "K.set_image_dim_ordering('th')\n",
        "from keras.utils import np_utils\n",
        "#from sklearn.cross_validation import StratifiedKFold\n",
        "from SpatialPyramidPooling import SpatialPyramidPooling\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import SimpleRNN\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvBdop9jYMC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numPCAcomponents = 30\n",
        "# Patches windows size\n",
        "windowSize = 7\n",
        "# The proportion of Test sets\n",
        "testRatio = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmAP8Q-nP-29",
        "colab_type": "code",
        "outputId": "88fc817f-9c47-4fa9-a071-71a1ed7060f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "cd datasets/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'datasets/'\n",
            "/content/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPvZsjnGQZXa",
        "colab_type": "code",
        "outputId": "384e6bb1-a5b6-48fd-b2e3-d7733521c852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tRrL1iaYaRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load(\"./predata/XtrainWindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio)  + \".npy\")\n",
        "y_train = np.load(\"./predata/ytrainWindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
        "X_test = np.load(\"./predata/XtestWindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n",
        "y_test = np.load(\"./predata/ytestWindowSize\" + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBkHzSuv85Uh",
        "colab_type": "code",
        "outputId": "1bcd1340-03f6-4acf-b2ed-31f292837bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Reshape data into (numberofsumples, channels, height, width)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[3], \n",
        "                               X_train.shape[1], X_train.shape[2]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[3], \n",
        "                             X_test.shape[1], X_test.shape[2]))\n",
        "\n",
        "# convert class labels to on-hot encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# Define the input shape \n",
        "input_shape= X_train[0].shape\n",
        "print(input_shape)\n",
        "\n",
        "# number of filters\n",
        "C1 = 3*numPCAcomponents"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 7, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn4ijxHATRwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, let's define a RNN Cell, as a layer subclass.\n",
        "\n",
        "class MinimalRNNCell(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                      initializer='uniform',\n",
        "                                      name='kernel')\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer='uniform',\n",
        "            name='recurrent_kernel')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        output = h + K.dot(prev_output, self.recurrent_kernel)\n",
        "        return output, [output]\n",
        "# Let's use this cell in a RNN layer:\n",
        "\n",
        "#cell = MinimalRNNCell(32)\n",
        "#x = keras.Input((None, 5))\n",
        "#layer = RNN(cell)\n",
        "#y = layer(x)\n",
        "\n",
        "# Here's how to use the cell to build a stacked RNN:\n",
        "\n",
        "#cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n",
        "#x = keras.Input((None, 5))\n",
        "#layer = RNN(cells)\n",
        "#y = layer(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fMqfjPy8-6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obtain_datagen(datagen, train_path, h5=True):\n",
        "\treturn datagen.flow_from_directory(\n",
        "\t\t\t\ttrain_path,\n",
        "\t\t\t\ttarget_size=(windowSize,windowSize),\n",
        "\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\tclass_mode='categorical') \t\n",
        "    \n",
        "def createCNNRNNModel():\n",
        "  \n",
        "    input_dim = (30, windowSize, windowSize)\n",
        "\n",
        "    num_timesteps = 1\n",
        "    input_lstm_shape=(num_timesteps,) + input_dim\n",
        "    #model_input = Input(shape=input_lstm_shape, name='seq_input')\n",
        "    print('input_lstm_shape',input_lstm_shape)\n",
        "    model = Sequential()\n",
        "    model.add(TimeDistributed(Conv2D(C1, (3, 3), padding='same', input_shape=input_shape, kernel_regularizer=l2(0.001)), input_shape =input_lstm_shape, name=\"TD1\"))\n",
        "    model.add(TimeDistributed(LeakyReLU(0.1), name=\"TD2\"))\n",
        "    model.add(TimeDistributed(BatchNormalization(momentum=0.9), name=\"TD4\"))\n",
        "    model.add(TimeDistributed(Dropout(0.5), name=\"TD3\"))    \n",
        "    \n",
        "    #model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),name='MaxPooling2D')))\n",
        "    \n",
        "    model.add(TimeDistributed(Conv2D(3*C1, (3, 3)), name=\"TD5\"))\n",
        "    model.add(TimeDistributed(BatchNormalization(momentum=0.9), name=\"TD7\"))\n",
        "    model.add(TimeDistributed(LeakyReLU(0.1), name=\"TD6\"))    \n",
        "    model.add(TimeDistributed(Dropout(0.5)))\n",
        "    model.add(TimeDistributed(SpatialPyramidPooling([1, 2, 3, 5]), name=\"TD8\"))\n",
        "    \n",
        "    #model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001))))\n",
        "    #model.add(TimeDistributed(LeakyReLU(0.1), name=\"TD10\"))\n",
        "    #model.add(TimeDistributed(BatchNormalization(momentum=0.9), name=\"TD111\"))\n",
        "    #model.add(TimeDistributed(Dropout(0.5), name=\"TD122\"))\n",
        "    #model.add(Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001))))\n",
        "    #model.add(TimeDistributed(LeakyReLU(0.1), name=\"TD100\"))\n",
        "    #model.add(TimeDistributed(BatchNormalization(momentum=0.9), name=\"TD11\"))\n",
        "    #model.add(TimeDistributed(Dropout(0.5), name=\"TD12\"))\n",
        "    #rnnCell = MinimalRNNCell(64)\n",
        "    cells = [MinimalRNNCell(32), MinimalRNNCell(64), MinimalRNNCell(128)]\n",
        "    #layer = RNN(rnnCell, return_sequences=True)\n",
        "    model.add(RNN(cells, return_sequences=True))\n",
        "    #model.add(TimeDistributed(SimpleRNN(300, return_sequences=True, regularizer=l2(0.001))))\n",
        "            \n",
        "    \n",
        "    #rnn = SimpleRNN(\n",
        "    #            300,\n",
        "    #            return_sequences=True,\n",
        "    #            dropout=self.dropout,\n",
        "    #            recurrent_dropout=self.recurrent_dropout)(char_emb)\n",
        "    #        dropped = Dropout(0.5)(rnn)\n",
        "    #        mot = MeanOverTime(mask_zero=True)(dropped)\n",
        "    #        densed = Dense(self.num_outputs, name='dense')(mot)\n",
        "    #        output = Activation('sigmoid')(densed)\n",
        "\n",
        "    #x = GRU(256, kernel_regularizer=l2(0.001))(x)\n",
        "\n",
        "    #x = SimpleRNN(256, return_sequences=True, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01),\n",
        "    #                      activity_regularizer=l2(0.01), kernel_constraint='max_norm',\n",
        "    #                      bias_constraint='max_norm', recurrent_constraint='max_norm')(x)\n",
        "\n",
        "    \n",
        "    model.add(Dense(128, name=\"TD13\"))\n",
        "    model.add(LeakyReLU(0.1, name=\"TD16\"))\n",
        "    model.add(BatchNormalization(momentum=0.9, name=\"TD17\"))\n",
        "    model.add(Dropout(0.5, name=\"TD18\"))\n",
        "    model.add(Dense(16, name=\"TD19\"))\n",
        "    model.add(Softmax())\n",
        "    \n",
        "    return model\n",
        "model = createCNNRNNModel()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_J_0mJ29G59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createModel():\n",
        "#    model = Sequential()\n",
        "    # define CNN model\n",
        "    '''\n",
        "    Load the output of the CNN\n",
        "    '''\n",
        "    #cnn_model = load_model(os.path.join('model_cnn5', 'checkpoint0.058_best.hdf5'))\n",
        "    \n",
        "    cnn_model = Sequential()\n",
        "\n",
        "    cnn_model.add(Conv2D(C1, (3, 3), padding='same', input_shape=input_shape, kernel_regularizer=l2(0.001)))\n",
        "    cnn_model.add(LeakyReLU(0.1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(Dropout(0.3))\n",
        "    cnn_model.add(Conv2D(3*C1, (3, 3), padding='same'))\n",
        "    cnn_model.add(LeakyReLU(0.1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(Dropout(0.3))\n",
        "    \n",
        "    cnn_model.add(SpatialPyramidPooling([1, 2, 4, 5, 7]))\n",
        "\n",
        "    #model.add(Flatten())\n",
        "    cnn_model.add(Dense(9*numPCAcomponents))\n",
        "    cnn_model.add(LeakyReLU(0.1))\n",
        "    cnn_model.add(BatchNormalization(momentum=0.9))\n",
        "    cnn_model.add(Dropout(0.3))\n",
        "    cnn_model.add(Dense(6*numPCAcomponents))\n",
        "    cnn_model.add(LeakyReLU(0.1))\n",
        "    cnn_model.add(Dropout(0.3))\n",
        "    cnn_model.add(Dense(16, activation='softmax'))\n",
        "    \n",
        "    return cnn_model\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrEQwJ_OALkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for layer in cnn_model.layers:\n",
        "#\tlayer.trainable = False\t\n",
        "\n",
        "Xtrain = np.reshape(X_train,(-1, 1, X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
        "ytrain = np.reshape(y_train,(-1, 1, y_train.shape[1]))\n",
        "\n",
        "Xtest = np.reshape(X_test, (-1, 1, X_test.shape[1], X_test.shape[2], X_test.shape[3]))\n",
        "ytest = np.reshape(y_test, (-1, 1, y_test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xcymeVuAZd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = ['SGD', 'RMSprop']\n",
        "#l_rates = [.001,.01,.0003,.003,.03,.3]\n",
        "l_rates = [.05,.03]\n",
        "#l_rates = [.03,.3]\n",
        "\n",
        "for lr in l_rates:\n",
        "  \n",
        "  l_rate = lr\n",
        "  print(\"Learning Rate: \" +str(lr))\n",
        "  #l_rate = lr #round(i,4) # loss: 0.0030 - acc: 0.9990 - val_loss: 0.1607 - val_acc: 0.9629\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=25, min_lr=0.000001, verbose=1)\n",
        "  checkpointer = ModelCheckpoint(filepath=\"checkpoint %f\"%(l_rate)+\"_lstm.hdf5\", verbose=1, save_best_only=True, mode='max')\n",
        "  sgd = SGD(lr=l_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  rmsprop = RMSprop(lr=l_rate,decay=1e-6, rho=0.9, epsilon=1e-08)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "  # Start to train model \n",
        "  history = model.fit(Xtrain, ytrain, \n",
        "              batch_size=32, \n",
        "              epochs=200, \n",
        "              verbose=1, \n",
        "              validation_data=(Xtest, ytest),\n",
        "              callbacks=[reduce_lr, checkpointer],\n",
        "              shuffle=True)\n",
        "  #ii += 1\n",
        "  f = open(\"train_cnn5_ssp_lstm4.txt\", \"a+\")\n",
        "  f.write(\"Learning Rate: %1.6f Accuracy: %2.6f Value Accuracy: %2.6f\\r\\n\"%(history.history[\"lr\"][0],max(history.history[\"acc\"])*100,max(history.history['val_acc'])*100))\n",
        "  f.close()\n",
        "\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train', 'test'], loc='upper left') \n",
        "  plt.savefig(\"model_accuracy_lstm4_\"+str(l_rate)+\".svg\")\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss \n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train', 'test'], loc='upper left') \n",
        "  plt.savefig(\"model_loss_lstm4_\"+str(l_rate)+\".svg\")\n",
        "  plt.show()\n",
        "\n",
        "  import h5py\n",
        "  from keras.models import load_model\n",
        "  model.save('HSI_model_epochs100_ssp_lstm_'+str(l_rate)+'.h5')\n",
        "\n",
        "# using plot_model module to save the model figure\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_ssp_lstm4.png', show_shapes=True)\n",
        "print(history.history.keys())\n",
        "\n",
        "# show the model figure\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "model_img = plt.imread('model_ssp_lstm4.png')\n",
        "plt.imshow(model_img, shape=(7, 7))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX-XpVrff59n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}