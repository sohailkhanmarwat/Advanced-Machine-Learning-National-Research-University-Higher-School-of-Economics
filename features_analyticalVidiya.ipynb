{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "features_analyticalVidiya.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohailkhanmarwat/Advanced-Machine-Learning-National-Research-University-Higher-School-of-Economics/blob/master/features_analyticalVidiya.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DosUlEtgarhT",
        "colab_type": "code",
        "outputId": "b1c1841d-0d97-4090-b773-a0a2c28a2ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCii8pe_a42C",
        "colab_type": "code",
        "outputId": "8bade70a-61a2-451c-d38a-990db450193d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Z_qWz6bN8x",
        "colab_type": "code",
        "outputId": "d925ee5b-c618-4be4-ffc5-e0786020f633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/sohailkhanmarwat/datasets.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 63 (delta 26), reused 21 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n",
            "Checking out files: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r4-cCLNbvN4",
        "colab_type": "code",
        "outputId": "bb51ab78-8f65-4da8-df8d-c0aa039e0f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#!rm -rf datasets/\n",
        "#!pwd\n",
        "#!ls\n",
        "#cd datasets\n",
        "\n",
        "#cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "datasets  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44wEATeAb1KT",
        "colab_type": "code",
        "outputId": "52e5d726-7922-4cf7-f8af-0c0d271482af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd datasets/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYs2tEHBhtj_",
        "colab_type": "code",
        "outputId": "2da479e1-ef6e-4bfe-873b-7a4f3d1b15e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install rarfile"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rarfile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/a4/8b4abc72310da6fa53b6de8de1019e0516885d05369d6c91cba23476abe5/rarfile-3.0.tar.gz (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: rarfile\n",
            "  Building wheel for rarfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/84/da/8aff50941f548db5384b076d5a6a6afea0cd12672e0326edc4\n",
            "Successfully built rarfile\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgSmxAIqKb0l",
        "colab_type": "code",
        "outputId": "13473932-7e36-4d26-9e69-9eb159c086fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd datasets/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUWrsboXb4vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rarfile\n",
        "file_name = \"images.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYv9zEgTHpWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"Cargo.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"Carrier.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"Cruise.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"Military.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"Tankers.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"spp.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()\n",
        "file_name = \"utilities.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLlgfwj1m-cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"pyimagesearch.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWyJSiS3nWZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"features_rest.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtL11SpPIM3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv Cargo ./images/\n",
        "!mv Carrier ./images/\n",
        "!mv Cruise ./images/\n",
        "!mv Military ./images/\n",
        "!mv Tankers ./images/\n",
        "!rm -rf Cargo.rar\n",
        "!rm -rf Carrier.rar\n",
        "!rm -rf Cruise.rar\n",
        "!rm -rf Military.rar\n",
        "!rm -rf Tankers.rar\n",
        "!rm -rf pyimagesearch.rar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTRvnPkGmqGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -rf datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyZl_CNdLSH9",
        "colab_type": "code",
        "outputId": "7fc1b74f-f2cb-4b97-e3cc-72dcc5f67a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRyBbCP0k1D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rarfile\n",
        "file_name = \"hdf5.rar\"\n",
        "with rarfile.RarFile(file_name) as rf:\n",
        "  rf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvHBUZGTP9EY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ea2114d-77d2-4eeb-838c-4d77a11fdaf9"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwsiwdEHQAzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8b4f8ae-ce06-49a1-c7a9-664e48c0c605"
      },
      "source": [
        "cd pyimagesearch/practitioner/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets/pyimagesearch/practitioner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG1lmNKGj5gK",
        "colab_type": "code",
        "outputId": "5ad0f622-8e97-43c2-9206-b39f3e84748e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jun  9 21:03:11 2019\n",
        "\n",
        "@author: Sohail Khan\n",
        "\"\"\"\n",
        "\n",
        "# import the necessary packages\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "import argparse\n",
        "import pickle\n",
        "import h5py\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-d\", \"--db\", required=False, default=\"./features_rest.hdf5\", help=\"path HDF5 database\")\n",
        "#ap.add_argument(\"-m\", \"--model\", required=False, default=\"./datasets/god.cpickle\", help=\"path to output model\")\n",
        "#ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1, help=\"# of jobs to run when tuning hyperparameters\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "db = \"./features_rest.hdf5\"\n",
        "mdl = \"./datasets/god1.cpickle\"\n",
        "jobs = -1\n",
        "# open the HDF5 database for reading then determine the index of\n",
        "# the training and testing split, provided that this data was\n",
        "# already shuffled *prior* to writing it to disk\n",
        "db = h5py.File(db, \"r\")\n",
        "i = int(db[\"labels\"].shape[0] * 0.75)\n",
        "\n",
        "# define the set of parameters that we want to tune then start a\n",
        "# grid search where we evaluate our model for each value of C\n",
        "print(\"[INFO] tuning hyperparameters...\")\n",
        "params = {\"C\": [0.1]}\n",
        "model = GridSearchCV(LogisticRegression(), params, cv=3, n_jobs=jobs)\n",
        "model.fit(db[\"features\"][:i], db[\"labels\"][:i])\n",
        "print(\"[INFO] best hyperparameters: {}\".format(model.best_params_))\n",
        "\n",
        "# evaluate the model\n",
        "print(\"[INFO] evaluating...\")\n",
        "preds = model.predict(db[\"features\"][i:])\n",
        "print(classification_report(db[\"labels\"][i:], preds, target_names=db[\"label_names\"]))\n",
        "\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving model...\")\n",
        "f = open(mdl, \"wb\")\n",
        "f.write(pickle.dumps(model.best_estimator_))\n",
        "f.close()\n",
        "\n",
        "# close the database\n",
        "db.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] tuning hyperparameters...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}